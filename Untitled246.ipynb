{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bf60c3-f303-4663-9bc6-f3f35cce315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading dataset...\n",
      "[INFO] Shape: (50000, 21)\n",
      "[INFO] Columns: ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'FloodProbability']\n",
      "[INFO] Running Hybrid AIS + WOA optimization...\n",
      "[ITER 1] Best MAE: 0.002279\n",
      "[ITER 2] Best MAE: 0.002279\n",
      "[ITER 3] Best MAE: 0.002279\n",
      "[ITER 4] Best MAE: 0.002279\n",
      "[ITER 5] Best MAE: 0.002279\n",
      "[ITER 6] Best MAE: 0.002279\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 7ms/step - loss: 0.0034 - mae: 0.0387 - val_loss: 7.8476e-05 - val_mae: 0.0064\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.1648e-04 - mae: 0.0108 - val_loss: 8.8689e-05 - val_mae: 0.0083\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.4646e-04 - mae: 0.0088 - val_loss: 2.3047e-05 - val_mae: 0.0037\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2897e-04 - mae: 0.0083 - val_loss: 1.2689e-05 - val_mae: 0.0029\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1348e-04 - mae: 0.0077 - val_loss: 1.0239e-05 - val_mae: 0.0026\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.0868e-04 - mae: 0.0075 - val_loss: 2.9943e-05 - val_mae: 0.0046\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0776e-04 - mae: 0.0074 - val_loss: 3.0115e-05 - val_mae: 0.0051\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0862e-04 - mae: 0.0074 - val_loss: 1.5488e-04 - val_mae: 0.0105\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1072e-04 - mae: 0.0075 - val_loss: 2.2451e-05 - val_mae: 0.0038\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.0927e-04 - mae: 0.0074 - val_loss: 5.1306e-06 - val_mae: 0.0018\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0785e-04 - mae: 0.0073 - val_loss: 3.3388e-05 - val_mae: 0.0046\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0982e-04 - mae: 0.0074 - val_loss: 5.1943e-06 - val_mae: 0.0018\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0860e-04 - mae: 0.0074 - val_loss: 2.3061e-05 - val_mae: 0.0041\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0775e-04 - mae: 0.0073 - val_loss: 1.1164e-05 - val_mae: 0.0025\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.0839e-04 - mae: 0.0073 - val_loss: 9.8871e-06 - val_mae: 0.0026\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.1102e-04 - mae: 0.0074 - val_loss: 9.0564e-06 - val_mae: 0.0024\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.0583e-04 - mae: 0.0072 - val_loss: 2.0677e-05 - val_mae: 0.0034\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0525e-04 - mae: 0.0072 - val_loss: 3.0749e-05 - val_mae: 0.0050\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0867e-04 - mae: 0.0073 - val_loss: 5.7355e-06 - val_mae: 0.0019\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.1163e-04 - mae: 0.0074 - val_loss: 9.2041e-06 - val_mae: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n",
      "[INFO] MAE=0.0018 | RMSE=0.0023 | RÂ²=0.9979\n",
      "[âœ…] All Hybrid AIS + WOA results saved successfully in: C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Conv1D, Flatten, Dropout, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“‚ PATHS\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"archive\", \"flood.csv\")\n",
    "VIS_DIR = os.path.join(BASE_DIR, \"visuals\")\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“Š LOAD DATA\n",
    "# =========================================================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "df = df.dropna()\n",
    "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, os.path.join(BASE_DIR, \"ais_woa_stormshield_scaler.pkl\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§± CNN + LSTM MODEL\n",
    "# =========================================================\n",
    "def build_model(lr=0.001, dropout_rate=0.3, units=64):\n",
    "    cnn_input = Input(shape=(X_train.shape[1], 1))\n",
    "    conv = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    flat = Flatten()(conv)\n",
    "\n",
    "    lstm_input = Input(shape=(X_train.shape[1], 1))\n",
    "    lstm = LSTM(units, return_sequences=False)(lstm_input)\n",
    "\n",
    "    merged = concatenate([flat, lstm])\n",
    "    dense = Dense(64, activation='relu')(merged)\n",
    "    drop = Dropout(dropout_rate)(dense)\n",
    "    output = Dense(1, activation='linear')(drop)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§¬ HYBRID AIS + WOA OPTIMIZER\n",
    "# =========================================================\n",
    "def hybrid_ais_woa(objective_func, dim, bounds, n_agents=6, max_iter=8):\n",
    "    lb, ub = np.array(bounds[0]), np.array(bounds[1])\n",
    "    population = np.random.uniform(lb, ub, (n_agents, dim))\n",
    "    fitness = np.array([objective_func(ind) for ind in population])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = population[best_idx].copy()\n",
    "    best_score = fitness[best_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        a = 2 - t * (2 / max_iter)  # linearly decreasing\n",
    "        for i in range(n_agents):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            A = 2 * a * r1 - a\n",
    "            C = 2 * r2\n",
    "            p = np.random.rand()\n",
    "\n",
    "            if p < 0.5:\n",
    "                if abs(A) >= 1:\n",
    "                    rand_idx = np.random.randint(n_agents)\n",
    "                    X_rand = population[rand_idx]\n",
    "                    D_X_rand = abs(C * X_rand - population[i])\n",
    "                    X_new = X_rand - A * D_X_rand\n",
    "                else:\n",
    "                    D_best = abs(C * best - population[i])\n",
    "                    X_new = best - A * D_best\n",
    "            else:\n",
    "                # Spiral updating position\n",
    "                b = 1  # logarithmic spiral constant\n",
    "                l = np.random.uniform(-1, 1)\n",
    "                D_best = abs(best - population[i])\n",
    "                X_new = D_best * np.exp(b * l) * np.cos(2 * np.pi * l) + best\n",
    "\n",
    "            # AIS mutation for diversity\n",
    "            mutation = np.random.randn(dim) * 0.05\n",
    "            X_new += mutation\n",
    "\n",
    "            X_new = np.clip(X_new, lb, ub)\n",
    "            new_fit = objective_func(X_new)\n",
    "            if new_fit < fitness[i]:\n",
    "                fitness[i] = new_fit\n",
    "                population[i] = X_new\n",
    "\n",
    "        best_idx = np.argmin(fitness)\n",
    "        if fitness[best_idx] < best_score:\n",
    "            best_score = fitness[best_idx]\n",
    "            best = population[best_idx].copy()\n",
    "\n",
    "        print(f\"[ITER {t+1}] Best MAE: {best_score:.6f}\")\n",
    "\n",
    "    return best, best_score\n",
    "\n",
    "# =========================================================\n",
    "# ðŸŽ¯ OBJECTIVE FUNCTION (MAE MINIMIZATION)\n",
    "# =========================================================\n",
    "def proxy_objective(params):\n",
    "    lr, dropout_rate, units = params\n",
    "    units = int(units)\n",
    "    model = build_model(lr, dropout_rate, units)\n",
    "    model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "              y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    loss, mae = model.evaluate([X_test[..., np.newaxis], X_test[..., np.newaxis]], y_test, verbose=0)\n",
    "    return mae  # minimize MAE\n",
    "\n",
    "# =========================================================\n",
    "# âš™ï¸ RUN HYBRID OPTIMIZATION\n",
    "# =========================================================\n",
    "print(\"[INFO] Running Hybrid AIS + WOA optimization...\")\n",
    "best_params, best_score = hybrid_ais_woa(\n",
    "    objective_func=lambda x: proxy_objective(x),\n",
    "    dim=3,\n",
    "    bounds=([0.0001, 0.1, 32], [0.01, 0.5, 128]),\n",
    "    n_agents=5,\n",
    "    max_iter=6\n",
    ")\n",
    "\n",
    "best_lr, best_dropout, best_units = best_params\n",
    "best_units = int(best_units)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"ais_woa_stormshield_config.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        'optimizer': 'Hybrid AIS + WOA',\n",
    "        'best_params': {\n",
    "            'learning_rate': float(best_lr),\n",
    "            'dropout_rate': float(best_dropout),\n",
    "            'units': int(best_units)\n",
    "        },\n",
    "        'best_MAE': float(best_score)\n",
    "    }, f)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§  FINAL TRAINING\n",
    "# =========================================================\n",
    "model = build_model(best_lr, best_dropout, best_units)\n",
    "early = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history_model = model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "                          y_train, validation_split=0.2,\n",
    "                          epochs=50, batch_size=32,\n",
    "                          callbacks=[early], verbose=1)\n",
    "\n",
    "model.save(os.path.join(BASE_DIR, \"ais_woa_stormshield_model.h5\"))\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“ˆ EVALUATION & VISUALS\n",
    "# =========================================================\n",
    "y_pred = model.predict([X_test[..., np.newaxis], X_test[..., np.newaxis]])\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"[INFO] MAE={mae:.4f} | RMSE={rmse:.4f} | RÂ²={r2:.4f}\")\n",
    "\n",
    "# Comparison Graph\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(y_test[:100], label='Actual')\n",
    "plt.plot(y_pred[:100], label='Predicted')\n",
    "plt.legend()\n",
    "plt.title(\"Flood Probability (Actual vs Predicted)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"ais_woa_stormshield_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Loss Graph\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history_model.history['loss'], label='Train')\n",
    "plt.plot(history_model.history['val_loss'], label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve (MSE)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"ais_woa_stormshield_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap\n",
    "corr = pd.DataFrame(np.hstack((y_test, y_pred)), columns=[\"True\", \"Predicted\"]).corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"True vs Predicted Correlation\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"ais_woa_stormshield_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ’¾ SAVE RESULTS\n",
    "# =========================================================\n",
    "pred_json = {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "with open(os.path.join(BASE_DIR, \"ais_woa_stormshield_prediction.json\"), \"w\") as f:\n",
    "    json.dump(pred_json, f, indent=4)\n",
    "\n",
    "pd.DataFrame({\"True\": y_test.flatten(), \"Predicted\": y_pred.flatten()}).to_csv(\n",
    "    os.path.join(BASE_DIR, \"ais_woa_stormshield_result.csv\"), index=False\n",
    ")\n",
    "\n",
    "print(\"[âœ…] All Hybrid AIS + WOA results saved successfully in:\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d4eef-6d14-46c2-862f-b486aa145446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
