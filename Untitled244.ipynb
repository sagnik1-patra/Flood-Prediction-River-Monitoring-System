{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f33dc62-c7fc-486f-a318-672b8065891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading dataset...\n",
      "[INFO] Shape: (50000, 21)\n",
      "[INFO] Columns: ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'FloodProbability']\n",
      "[INFO] Running AIS+GWO optimization...\n",
      "[ITER 1] Best MAE: 0.002448\n",
      "[ITER 2] Best MAE: 0.002448\n",
      "[ITER 3] Best MAE: 0.002448\n",
      "[ITER 4] Best MAE: 0.002448\n",
      "[ITER 5] Best MAE: 0.002448\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.0040 - mae: 0.0388 - val_loss: 5.5087e-05 - val_mae: 0.0055\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 2.2374e-04 - mae: 0.0108 - val_loss: 4.2107e-05 - val_mae: 0.0054\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.9551e-04 - mae: 0.0100 - val_loss: 6.8411e-05 - val_mae: 0.0067\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.9004e-04 - mae: 0.0098 - val_loss: 2.4976e-05 - val_mae: 0.0041\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.8035e-04 - mae: 0.0095 - val_loss: 3.4890e-05 - val_mae: 0.0050\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.8637e-04 - mae: 0.0097 - val_loss: 2.2347e-05 - val_mae: 0.0038\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.8252e-04 - mae: 0.0095 - val_loss: 3.1062e-05 - val_mae: 0.0050\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.7988e-04 - mae: 0.0094 - val_loss: 1.1786e-04 - val_mae: 0.0099\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.6812e-04 - mae: 0.0091 - val_loss: 1.2852e-05 - val_mae: 0.0030\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.7436e-04 - mae: 0.0093 - val_loss: 1.9065e-05 - val_mae: 0.0036\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.6738e-04 - mae: 0.0090 - val_loss: 5.8191e-05 - val_mae: 0.0061\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.6553e-04 - mae: 0.0090 - val_loss: 3.6768e-05 - val_mae: 0.0053\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.6634e-04 - mae: 0.0090 - val_loss: 2.3902e-05 - val_mae: 0.0036\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.6511e-04 - mae: 0.0089 - val_loss: 4.1164e-05 - val_mae: 0.0055\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.6532e-04 - mae: 0.0089 - val_loss: 5.9469e-05 - val_mae: 0.0063\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.5789e-04 - mae: 0.0087 - val_loss: 1.6974e-05 - val_mae: 0.0030\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.5572e-04 - mae: 0.0087 - val_loss: 1.4181e-05 - val_mae: 0.0026\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.5957e-04 - mae: 0.0088 - val_loss: 2.3567e-05 - val_mae: 0.0037\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.6360e-04 - mae: 0.0089 - val_loss: 1.9351e-05 - val_mae: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n",
      "[INFO] MAE=0.0031 | RMSE=0.0036 | RÂ²=0.9948\n",
      "[âœ…] All files saved successfully in: C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Conv1D, Flatten, Dropout, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“‚ PATHS\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"archive\", \"flood.csv\")\n",
    "VIS_DIR = os.path.join(BASE_DIR, \"visuals\")\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“Š LOAD DATA\n",
    "# =========================================================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Last column = FloodProbability (regression target)\n",
    "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, os.path.join(BASE_DIR, \"ais_gwo_stormshield_scaler.pkl\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§± MODEL BUILDER (CNN + LSTM)\n",
    "# =========================================================\n",
    "def build_model(lr=0.001, dropout_rate=0.3, units=64):\n",
    "    # CNN branch\n",
    "    cnn_input = Input(shape=(X_train.shape[1], 1))\n",
    "    conv = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    flat = Flatten()(conv)\n",
    "\n",
    "    # LSTM branch\n",
    "    lstm_input = Input(shape=(X_train.shape[1], 1))\n",
    "    lstm = LSTM(units, return_sequences=False)(lstm_input)\n",
    "\n",
    "    # Merge\n",
    "    merged = concatenate([flat, lstm])\n",
    "    dense1 = Dense(64, activation='relu')(merged)\n",
    "    drop = Dropout(dropout_rate)(dense1)\n",
    "    output = Dense(1, activation='linear')(drop)  # regression output\n",
    "\n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§¬ HYBRID AIS + GWO OPTIMIZER\n",
    "# =========================================================\n",
    "def hybrid_ais_gwo(objective_func, dim, bounds, n_agents=4, max_iter=6):\n",
    "    lb, ub = bounds\n",
    "    population = np.random.uniform(lb, ub, (n_agents, dim))\n",
    "    fitness = np.array([objective_func(ind) for ind in population])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = population[best_idx].copy()\n",
    "    best_score = fitness[best_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        a = 2 - 2 * (t / max_iter)\n",
    "        for i in range(n_agents):\n",
    "            A = 2 * a * np.random.rand(dim) - a\n",
    "            C = 2 * np.random.rand(dim)\n",
    "            j = np.random.randint(n_agents)\n",
    "            D = abs(C * population[j] - population[i])\n",
    "            X_new = population[j] - A * D\n",
    "\n",
    "            # AIS mutation\n",
    "            mutation = np.random.randn(dim) * 0.05\n",
    "            X_new = np.clip(X_new + mutation, lb, ub)\n",
    "\n",
    "            new_fit = objective_func(X_new)\n",
    "            if new_fit < fitness[i]:\n",
    "                fitness[i] = new_fit\n",
    "                population[i] = X_new\n",
    "\n",
    "        best_idx = np.argmin(fitness)\n",
    "        if fitness[best_idx] < best_score:\n",
    "            best_score = fitness[best_idx]\n",
    "            best = population[best_idx].copy()\n",
    "\n",
    "        print(f\"[ITER {t+1}] Best MAE: {best_score:.6f}\")\n",
    "\n",
    "    return best, best_score\n",
    "\n",
    "# =========================================================\n",
    "# ðŸŽ¯ OBJECTIVE FUNCTION (MAE MINIMIZATION)\n",
    "# =========================================================\n",
    "def proxy_objective(params):\n",
    "    lr, dropout_rate, units = params\n",
    "    units = int(units)\n",
    "    model = build_model(lr, dropout_rate, units)\n",
    "    model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "              y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    loss, mae = model.evaluate([X_test[..., np.newaxis], X_test[..., np.newaxis]], y_test, verbose=0)\n",
    "    return mae  # minimize MAE\n",
    "\n",
    "# =========================================================\n",
    "# âš™ï¸ RUN OPTIMIZATION\n",
    "# =========================================================\n",
    "print(\"[INFO] Running AIS+GWO optimization...\")\n",
    "best_params, best_score = hybrid_ais_gwo(\n",
    "    objective_func=lambda x: proxy_objective(x),\n",
    "    dim=3,\n",
    "    bounds=([0.0001, 0.1, 32], [0.01, 0.5, 128]),\n",
    "    n_agents=4,\n",
    "    max_iter=5\n",
    ")\n",
    "\n",
    "best_lr, best_dropout, best_units = best_params\n",
    "best_units = int(best_units)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"ais_gwo_stormshield_config.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        'optimizer': 'Hybrid AIS + GWO (Regression)',\n",
    "        'best_params': {\n",
    "            'learning_rate': float(best_lr),\n",
    "            'dropout_rate': float(best_dropout),\n",
    "            'units': int(best_units)\n",
    "        },\n",
    "        'best_MAE': float(best_score)\n",
    "    }, f)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§  FINAL TRAINING\n",
    "# =========================================================\n",
    "model = build_model(best_lr, best_dropout, best_units)\n",
    "early = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history_model = model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "                          y_train, validation_split=0.2,\n",
    "                          epochs=50, batch_size=32,\n",
    "                          callbacks=[early], verbose=1)\n",
    "\n",
    "model.save(os.path.join(BASE_DIR, \"ais_gwo_stormshield_model.h5\"))\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“ˆ EVALUATION & VISUALS\n",
    "# =========================================================\n",
    "y_pred = model.predict([X_test[..., np.newaxis], X_test[..., np.newaxis]])\n",
    "\n",
    "# Manual RMSE computation for old sklearn\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"[INFO] MAE={mae:.4f} | RMSE={rmse:.4f} | RÂ²={r2:.4f}\")\n",
    "\n",
    "# Comparison Plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(y_test[:100], label='Actual')\n",
    "plt.plot(y_pred[:100], label='Predicted')\n",
    "plt.legend()\n",
    "plt.title(\"Flood Probability (Actual vs Predicted)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"ais_gwo_stormshield_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Loss Curve\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history_model.history['loss'], label='Train')\n",
    "plt.plot(history_model.history['val_loss'], label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve (MSE)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"ais_gwo_stormshield_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap\n",
    "corr = pd.DataFrame(np.hstack((y_test, y_pred)), columns=[\"True\", \"Predicted\"]).corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"True vs Predicted Correlation\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"ais_gwo_stormshield_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ’¾ SAVE RESULTS\n",
    "# =========================================================\n",
    "pred_json = {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "with open(os.path.join(BASE_DIR, \"ais_gwo_stormshield_prediction.json\"), \"w\") as f:\n",
    "    json.dump(pred_json, f, indent=4)\n",
    "\n",
    "pd.DataFrame({\"True\": y_test.flatten(), \"Predicted\": y_pred.flatten()}).to_csv(\n",
    "    os.path.join(BASE_DIR, \"ais_gwo_stormshield_result.csv\"), index=False\n",
    ")\n",
    "\n",
    "print(\"[âœ…] All files saved successfully in:\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e6237-3371-448e-9007-9017e850dc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
