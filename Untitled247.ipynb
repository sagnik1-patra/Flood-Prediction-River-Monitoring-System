{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06d3b31-aedc-4652-8655-56f9c3f94d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading dataset...\n",
      "[INFO] Shape: (50000, 21)\n",
      "[INFO] Columns: ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'FloodProbability']\n",
      "[INFO] Running Hybrid PSO + CSA optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_3244\\2230340539.py:70: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_3244\\2230340539.py:71: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 1] Best MAE: 0.001664\n",
      "[ITER 2] Best MAE: 0.001664\n",
      "[ITER 3] Best MAE: 0.001664\n",
      "[ITER 4] Best MAE: 0.001664\n",
      "[ITER 5] Best MAE: 0.001664\n",
      "[ITER 6] Best MAE: 0.001664\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 8.0682e-05 - val_mae: 0.0080\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.5457e-04 - mae: 0.0092 - val_loss: 3.8949e-05 - val_mae: 0.0052\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 8.5079e-05 - mae: 0.0067 - val_loss: 1.5436e-05 - val_mae: 0.0032\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.8880e-05 - mae: 0.0065 - val_loss: 1.6607e-05 - val_mae: 0.0034\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 8.1082e-05 - mae: 0.0065 - val_loss: 1.4926e-05 - val_mae: 0.0031\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.5229e-05 - mae: 0.0062 - val_loss: 2.1375e-05 - val_mae: 0.0041\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.6334e-05 - mae: 0.0063 - val_loss: 5.4981e-06 - val_mae: 0.0019\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.1349e-05 - mae: 0.0061 - val_loss: 9.9941e-06 - val_mae: 0.0023\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.2237e-05 - mae: 0.0061 - val_loss: 1.5866e-05 - val_mae: 0.0037\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.6786e-05 - mae: 0.0058 - val_loss: 1.8743e-05 - val_mae: 0.0039\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.9730e-05 - mae: 0.0059 - val_loss: 2.2598e-05 - val_mae: 0.0042\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.9289e-05 - mae: 0.0059 - val_loss: 4.3516e-06 - val_mae: 0.0017\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.9006e-05 - mae: 0.0059 - val_loss: 9.6975e-06 - val_mae: 0.0027\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.5885e-05 - mae: 0.0058 - val_loss: 4.4732e-06 - val_mae: 0.0017\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.8148e-05 - mae: 0.0059 - val_loss: 8.7899e-05 - val_mae: 0.0076\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.0586e-05 - mae: 0.0060 - val_loss: 1.6390e-05 - val_mae: 0.0034\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.7927e-05 - mae: 0.0059 - val_loss: 1.7493e-05 - val_mae: 0.0035\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.6883e-05 - mae: 0.0057 - val_loss: 1.2523e-05 - val_mae: 0.0029\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.6658e-05 - mae: 0.0057 - val_loss: 2.5313e-05 - val_mae: 0.0037\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.5307e-05 - mae: 0.0056 - val_loss: 2.2932e-06 - val_mae: 0.0012\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 7.0150e-05 - mae: 0.0059 - val_loss: 2.3340e-05 - val_mae: 0.0045\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.4675e-05 - mae: 0.0057 - val_loss: 3.1801e-06 - val_mae: 0.0014\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.5660e-05 - mae: 0.0057 - val_loss: 1.3975e-05 - val_mae: 0.0034\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 6.5277e-05 - mae: 0.0057 - val_loss: 4.0797e-06 - val_mae: 0.0017\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.7082e-05 - mae: 0.0058 - val_loss: 4.2079e-06 - val_mae: 0.0017\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.6620e-05 - mae: 0.0057 - val_loss: 2.7658e-05 - val_mae: 0.0043\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 6.5453e-05 - mae: 0.0056 - val_loss: 1.1595e-05 - val_mae: 0.0031\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.7690e-05 - mae: 0.0058 - val_loss: 1.5482e-05 - val_mae: 0.0032\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.4277e-05 - mae: 0.0056 - val_loss: 2.2051e-05 - val_mae: 0.0042\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.4767e-05 - mae: 0.0056 - val_loss: 6.0795e-06 - val_mae: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n",
      "[INFO] MAE=0.0012 | RMSE=0.0015 | RÂ²=0.9990\n",
      "[âœ…] All Hybrid PSO + CSA results saved successfully in: C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Conv1D, Flatten, Dropout, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“‚ PATHS\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"archive\", \"flood.csv\")\n",
    "VIS_DIR = os.path.join(BASE_DIR, \"visuals\")\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“Š LOAD DATA\n",
    "# =========================================================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "df = df.dropna()\n",
    "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, os.path.join(BASE_DIR, \"pso_csa_stormshield_scaler.pkl\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§± CNN + LSTM MODEL\n",
    "# =========================================================\n",
    "def build_model(lr=0.001, dropout_rate=0.3, units=64):\n",
    "    cnn_input = Input(shape=(X_train.shape[1], 1))\n",
    "    conv = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    flat = Flatten()(conv)\n",
    "\n",
    "    lstm_input = Input(shape=(X_train.shape[1], 1))\n",
    "    lstm = LSTM(units, return_sequences=False)(lstm_input)\n",
    "\n",
    "    merged = concatenate([flat, lstm])\n",
    "    dense = Dense(64, activation='relu')(merged)\n",
    "    drop = Dropout(dropout_rate)(dense)\n",
    "    output = Dense(1, activation='linear')(drop)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§¬ HYBRID PSO + CSA OPTIMIZER\n",
    "# =========================================================\n",
    "def levy_flight(beta=1.5):\n",
    "    sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n",
    "               (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n",
    "    u = np.random.randn() * sigma_u\n",
    "    v = np.random.randn()\n",
    "    step = u / abs(v) ** (1 / beta)\n",
    "    return step\n",
    "\n",
    "def hybrid_pso_csa(objective_func, dim, bounds, n_particles=6, max_iter=8, w=0.7, c1=1.5, c2=1.5, pa=0.25):\n",
    "    lb, ub = np.array(bounds[0]), np.array(bounds[1])\n",
    "    pos = np.random.uniform(lb, ub, (n_particles, dim))\n",
    "    vel = np.zeros((n_particles, dim))\n",
    "    fitness = np.array([objective_func(p) for p in pos])\n",
    "    pbest = pos.copy()\n",
    "    pbest_fit = fitness.copy()\n",
    "    gbest_idx = np.argmin(fitness)\n",
    "    gbest = pos[gbest_idx].copy()\n",
    "    gbest_fit = fitness[gbest_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        for i in range(n_particles):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            vel[i] = (w * vel[i]) + c1 * r1 * (pbest[i] - pos[i]) + c2 * r2 * (gbest - pos[i])\n",
    "            pos[i] += vel[i]\n",
    "\n",
    "            # Apply Cuckoo Search mutation occasionally\n",
    "            if np.random.rand() < pa:\n",
    "                step = levy_flight()\n",
    "                pos[i] += step * (pos[i] - pos[np.random.randint(n_particles)])\n",
    "\n",
    "            pos[i] = np.clip(pos[i], lb, ub)\n",
    "            fit = objective_func(pos[i])\n",
    "            if fit < pbest_fit[i]:\n",
    "                pbest_fit[i] = fit\n",
    "                pbest[i] = pos[i]\n",
    "            if fit < gbest_fit:\n",
    "                gbest_fit = fit\n",
    "                gbest = pos[i].copy()\n",
    "\n",
    "        print(f\"[ITER {t+1}] Best MAE: {gbest_fit:.6f}\")\n",
    "\n",
    "    return gbest, gbest_fit\n",
    "\n",
    "# =========================================================\n",
    "# ðŸŽ¯ OBJECTIVE FUNCTION (MAE MINIMIZATION)\n",
    "# =========================================================\n",
    "def proxy_objective(params):\n",
    "    lr, dropout_rate, units = params\n",
    "    units = int(units)\n",
    "    model = build_model(lr, dropout_rate, units)\n",
    "    model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "              y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    loss, mae = model.evaluate([X_test[..., np.newaxis], X_test[..., np.newaxis]], y_test, verbose=0)\n",
    "    return mae\n",
    "\n",
    "# =========================================================\n",
    "# âš™ï¸ RUN HYBRID OPTIMIZATION\n",
    "# =========================================================\n",
    "print(\"[INFO] Running Hybrid PSO + CSA optimization...\")\n",
    "best_params, best_score = hybrid_pso_csa(\n",
    "    objective_func=lambda x: proxy_objective(x),\n",
    "    dim=3,\n",
    "    bounds=([0.0001, 0.1, 32], [0.01, 0.5, 128]),\n",
    "    n_particles=5,\n",
    "    max_iter=6\n",
    ")\n",
    "\n",
    "best_lr, best_dropout, best_units = best_params\n",
    "best_units = int(best_units)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"pso_csa_stormshield_config.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        'optimizer': 'Hybrid PSO + CSA',\n",
    "        'best_params': {\n",
    "            'learning_rate': float(best_lr),\n",
    "            'dropout_rate': float(best_dropout),\n",
    "            'units': int(best_units)\n",
    "        },\n",
    "        'best_MAE': float(best_score)\n",
    "    }, f)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§  FINAL TRAINING\n",
    "# =========================================================\n",
    "model = build_model(best_lr, best_dropout, best_units)\n",
    "early = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history_model = model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "                          y_train, validation_split=0.2,\n",
    "                          epochs=50, batch_size=32,\n",
    "                          callbacks=[early], verbose=1)\n",
    "\n",
    "model.save(os.path.join(BASE_DIR, \"pso_csa_stormshield_model.h5\"))\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“ˆ EVALUATION & VISUALS\n",
    "# =========================================================\n",
    "y_pred = model.predict([X_test[..., np.newaxis], X_test[..., np.newaxis]])\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"[INFO] MAE={mae:.4f} | RMSE={rmse:.4f} | RÂ²={r2:.4f}\")\n",
    "\n",
    "# Comparison Graph\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(y_test[:100], label='Actual')\n",
    "plt.plot(y_pred[:100], label='Predicted')\n",
    "plt.legend()\n",
    "plt.title(\"Flood Probability (Actual vs Predicted)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"pso_csa_stormshield_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Loss Graph\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history_model.history['loss'], label='Train')\n",
    "plt.plot(history_model.history['val_loss'], label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve (MSE)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"pso_csa_stormshield_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap\n",
    "corr = pd.DataFrame(np.hstack((y_test, y_pred)), columns=[\"True\", \"Predicted\"]).corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"True vs Predicted Correlation\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"pso_csa_stormshield_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ’¾ SAVE RESULTS\n",
    "# =========================================================\n",
    "pred_json = {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "with open(os.path.join(BASE_DIR, \"pso_csa_stormshield_prediction.json\"), \"w\") as f:\n",
    "    json.dump(pred_json, f, indent=4)\n",
    "\n",
    "pd.DataFrame({\"True\": y_test.flatten(), \"Predicted\": y_pred.flatten()}).to_csv(\n",
    "    os.path.join(BASE_DIR, \"pso_csa_stormshield_result.csv\"), index=False\n",
    ")\n",
    "\n",
    "print(\"[âœ…] All Hybrid PSO + CSA results saved successfully in:\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca54111-29b1-45db-a552-b5d512c803bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
