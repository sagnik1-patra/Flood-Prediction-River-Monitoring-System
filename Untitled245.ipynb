{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac09654-4067-474b-b649-18473ada9c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] Loading dataset...\n",
      "[INFO] Shape: (50000, 21)\n",
      "[INFO] Columns: ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'FloodProbability']\n",
      "[INFO] Running Hybrid AIS + CSA optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_23616\\154101714.py:70: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_23616\\154101714.py:71: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ITER 1] Best MAE: 0.002370\n",
      "[ITER 2] Best MAE: 0.002370\n",
      "[ITER 3] Best MAE: 0.002232\n",
      "[ITER 4] Best MAE: 0.002232\n",
      "[ITER 5] Best MAE: 0.002232\n",
      "[ITER 6] Best MAE: 0.002232\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 8ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 2.1860e-05 - val_mae: 0.0036\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2853e-04 - mae: 0.0085 - val_loss: 3.2324e-05 - val_mae: 0.0042\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2087e-04 - mae: 0.0081 - val_loss: 2.5433e-05 - val_mae: 0.0033\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2295e-04 - mae: 0.0082 - val_loss: 2.7362e-05 - val_mae: 0.0022\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1605e-04 - mae: 0.0078 - val_loss: 4.3235e-05 - val_mae: 0.0049\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.2052e-04 - mae: 0.0080 - val_loss: 2.7185e-05 - val_mae: 0.0022\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.2043e-04 - mae: 0.0080 - val_loss: 2.2283e-05 - val_mae: 0.0025\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1799e-04 - mae: 0.0079 - val_loss: 2.6980e-05 - val_mae: 0.0026\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2321e-04 - mae: 0.0081 - val_loss: 3.3109e-05 - val_mae: 0.0036\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1851e-04 - mae: 0.0079 - val_loss: 2.4909e-05 - val_mae: 0.0023\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1394e-04 - mae: 0.0077 - val_loss: 8.5554e-05 - val_mae: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n",
      "[INFO] MAE=0.0036 | RMSE=0.0048 | RÂ²=0.9909\n",
      "[âœ…] All hybrid AIS+CSA results saved successfully in: C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Conv1D, Flatten, Dropout, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“‚ PATHS\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Flood Prediction & River-Monitoring System\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"archive\", \"flood.csv\")\n",
    "VIS_DIR = os.path.join(BASE_DIR, \"visuals\")\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“Š LOAD DATA\n",
    "# =========================================================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "df = df.dropna()\n",
    "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, os.path.join(BASE_DIR, \"hybrid_stormshield_scaler.pkl\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§± CNN + LSTM MODEL\n",
    "# =========================================================\n",
    "def build_model(lr=0.001, dropout_rate=0.3, units=64):\n",
    "    cnn_input = Input(shape=(X_train.shape[1], 1))\n",
    "    conv = Conv1D(filters=32, kernel_size=3, activation='relu')(cnn_input)\n",
    "    flat = Flatten()(conv)\n",
    "\n",
    "    lstm_input = Input(shape=(X_train.shape[1], 1))\n",
    "    lstm = LSTM(units, return_sequences=False)(lstm_input)\n",
    "\n",
    "    merged = concatenate([flat, lstm])\n",
    "    dense = Dense(64, activation='relu')(merged)\n",
    "    drop = Dropout(dropout_rate)(dense)\n",
    "    output = Dense(1, activation='linear')(drop)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§¬ HYBRID AIS + CSA OPTIMIZER\n",
    "# =========================================================\n",
    "def levy_flight(beta=1.5):\n",
    "    sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n",
    "               (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n",
    "    u = np.random.randn() * sigma_u\n",
    "    v = np.random.randn()\n",
    "    step = u / abs(v) ** (1 / beta)\n",
    "    return step\n",
    "\n",
    "def hybrid_ais_csa(objective_func, dim, bounds, n_agents=6, max_iter=8, pa=0.25):\n",
    "    lb, ub = np.array(bounds[0]), np.array(bounds[1])\n",
    "    population = np.random.uniform(lb, ub, (n_agents, dim))\n",
    "    fitness = np.array([objective_func(ind) for ind in population])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = population[best_idx].copy()\n",
    "    best_score = fitness[best_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        for i in range(n_agents):\n",
    "            # Cuckoo Search step (Levy flight)\n",
    "            step = levy_flight()\n",
    "            new_solution = population[i] + step * (population[i] - population[np.random.randint(n_agents)])\n",
    "            new_solution = np.clip(new_solution, lb, ub)\n",
    "\n",
    "            # AIS mutation (small Gaussian change)\n",
    "            mutation = np.random.randn(dim) * 0.05\n",
    "            new_solution += mutation\n",
    "            new_solution = np.clip(new_solution, lb, ub)\n",
    "\n",
    "            new_fit = objective_func(new_solution)\n",
    "            if new_fit < fitness[i]:\n",
    "                fitness[i] = new_fit\n",
    "                population[i] = new_solution\n",
    "\n",
    "        # Discovery step (replace some nests)\n",
    "        rand_mask = np.random.rand(n_agents, dim) < pa\n",
    "        random_nests = np.random.uniform(lb, ub, (n_agents, dim))\n",
    "        population = np.where(rand_mask, random_nests, population)\n",
    "\n",
    "        # Update best\n",
    "        best_idx = np.argmin(fitness)\n",
    "        if fitness[best_idx] < best_score:\n",
    "            best_score = fitness[best_idx]\n",
    "            best = population[best_idx].copy()\n",
    "\n",
    "        print(f\"[ITER {t+1}] Best MAE: {best_score:.6f}\")\n",
    "\n",
    "    return best, best_score\n",
    "\n",
    "# =========================================================\n",
    "# ðŸŽ¯ OBJECTIVE FUNCTION (MAE MINIMIZATION)\n",
    "# =========================================================\n",
    "def proxy_objective(params):\n",
    "    lr, dropout_rate, units = params\n",
    "    units = int(units)\n",
    "    model = build_model(lr, dropout_rate, units)\n",
    "    model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "              y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    loss, mae = model.evaluate([X_test[..., np.newaxis], X_test[..., np.newaxis]], y_test, verbose=0)\n",
    "    return mae  # minimize MAE\n",
    "\n",
    "# =========================================================\n",
    "# âš™ï¸ RUN HYBRID OPTIMIZATION\n",
    "# =========================================================\n",
    "print(\"[INFO] Running Hybrid AIS + CSA optimization...\")\n",
    "best_params, best_score = hybrid_ais_csa(\n",
    "    objective_func=lambda x: proxy_objective(x),\n",
    "    dim=3,\n",
    "    bounds=([0.0001, 0.1, 32], [0.01, 0.5, 128]),\n",
    "    n_agents=5,\n",
    "    max_iter=6\n",
    ")\n",
    "\n",
    "best_lr, best_dropout, best_units = best_params\n",
    "best_units = int(best_units)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"hybrid_stormshield_config.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        'optimizer': 'Hybrid AIS + CSA',\n",
    "        'best_params': {\n",
    "            'learning_rate': float(best_lr),\n",
    "            'dropout_rate': float(best_dropout),\n",
    "            'units': int(best_units)\n",
    "        },\n",
    "        'best_MAE': float(best_score)\n",
    "    }, f)\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ§  FINAL TRAINING\n",
    "# =========================================================\n",
    "model = build_model(best_lr, best_dropout, best_units)\n",
    "early = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history_model = model.fit([X_train[..., np.newaxis], X_train[..., np.newaxis]],\n",
    "                          y_train, validation_split=0.2,\n",
    "                          epochs=50, batch_size=32,\n",
    "                          callbacks=[early], verbose=1)\n",
    "\n",
    "model.save(os.path.join(BASE_DIR, \"hybrid_stormshield_model.h5\"))\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ“ˆ EVALUATION & VISUALS\n",
    "# =========================================================\n",
    "y_pred = model.predict([X_test[..., np.newaxis], X_test[..., np.newaxis]])\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"[INFO] MAE={mae:.4f} | RMSE={rmse:.4f} | RÂ²={r2:.4f}\")\n",
    "\n",
    "# Comparison Plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(y_test[:100], label='Actual')\n",
    "plt.plot(y_pred[:100], label='Predicted')\n",
    "plt.legend()\n",
    "plt.title(\"Flood Probability (Actual vs Predicted)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"hybrid_stormshield_comparison_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Loss Curve\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history_model.history['loss'], label='Train')\n",
    "plt.plot(history_model.history['val_loss'], label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve (MSE)\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"hybrid_stormshield_loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap\n",
    "corr = pd.DataFrame(np.hstack((y_test, y_pred)), columns=[\"True\", \"Predicted\"]).corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"True vs Predicted Correlation\")\n",
    "plt.savefig(os.path.join(VIS_DIR, \"hybrid_stormshield_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# ðŸ’¾ SAVE RESULTS\n",
    "# =========================================================\n",
    "pred_json = {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "with open(os.path.join(BASE_DIR, \"hybrid_stormshield_prediction.json\"), \"w\") as f:\n",
    "    json.dump(pred_json, f, indent=4)\n",
    "\n",
    "pd.DataFrame({\"True\": y_test.flatten(), \"Predicted\": y_pred.flatten()}).to_csv(\n",
    "    os.path.join(BASE_DIR, \"hybrid_stormshield_result.csv\"), index=False\n",
    ")\n",
    "\n",
    "print(\"[âœ…] All hybrid AIS+CSA results saved successfully in:\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b8bd3-efca-4224-bfec-9c889afb6b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
